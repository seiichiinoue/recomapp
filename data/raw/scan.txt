A Bayesian Model of Diachronic Meaning Changeの実装
今回実装したのは，通時的な意味変化を捉えるトピックモデルです．2016年のTACL論文になります．以下論文です．
https://www.aclweb.org/anthology/Q16-1003.pdf
実装後に発見したのですが，一応著者が公開している実装もあるらしいです（しかしGoで書かれていて，超絶読みづらいです）．
僕の実装は以下になります:
https://github.com/seiichiinoue/scan
Dynamic Bayesian Model of Sense Change (SCAN)
前置きとして，このモデルは単語の意味変化を捉えるためのモデルになっています．
データが少し特殊で，word-specific documentsを用いて学習します．意味変化を検出したいtarget wordの周辺単語を任意の文脈窓幅について というような文書を仮定します．
この文書に対して，year label (正確な年は必要なく，どの文書集合がどの年代のものかがわかればよい) が付与されていて，その文書のyear labelを使って時期ごとにパラメータを設定し，それぞれの時期間に相関を持たせながら学習するようなモデルになっています．
本モデルでは，時点のtemporal meaning representationとして，K次元のトピック分布とV次元の単語分布を仮定します．また，時点間でのトピック分布の変化を制御するための精度パラメータであるを導入します．
上述の精度パラメータを使って，どのように時点間の相関をもたせるかですが，それは多項分布, の事前分布にlogistic normalを置くことで実現します．logistic normalに従う多項分布パラメータは，次元のランダムベクトルが次元の平均ベクトル，次元の分散共分散行列によるガウス分布から生成され:
それを次のようにロジスティック変換することにより単体上に射影する（0 ~ 1の確率に変換する）ことで生成されます．
このように事前分布にガウス分布を置くことで，分散を通してパラメータの変化の度合いをコントロールできます．
以下にSCANのグラフィカルモデルと生成モデルを示します．
まず，トピック精度パラメータを共役事前分布であるGamma分布から生成します．
次に，それぞれの時点において，logistic normal事前分布からトピック分布を生成し，それぞれのトピックについて，同様にlogistic normal事前分布から単語分布を生成します．
そして，各文書に対して，トピックを多項分布から生成し，文脈窓幅回文脈単語を多項分布から独立に生成する流れになります．
ここで，トピック分布 (論文中ではsense distributionと呼ばれている) と単語分布について，時点と時点のパラメータの平均を事前分布の平均としていますが，これは，intrinsic Gaussian Markov Random Field (iGMRF) であり，時期間のパラメータに相関を持たせ，変化を捉えることを可能としています．
推論
SCANの推定パラメータは，潜在変数である文書のトピック，トピック分布，単語分布，トピック分布のlogistic normal事前分布のパラメータです．
推定にはblocked Gibbs Samplerを用います．一般に，トピックモデルは多項分布-Dirichlet分布を用いて離散変数のモデル化を行うことが多いのですが，SCANは多項分布の事前分布に共役ではないガウス分布を仮定しているので，同様に推定することはできません．
そのため，Mimnoらから提案された補助変数を用いたlogistic normal priorに従うパラメータ推定法を用います．
大まかな流れとしては，文書のトピックを他のパラメータを固定した状態でサンプルし，次にトピックと単語の多項分布のパラメータを同様に他のパラメータを固定してサンプルし，最後に精度パラメータをサンプルする，という感じです．
トピックのサンプリング
文書のトピックは，他のパラメータを全て固定した上で以下の条件付き確率に従ってサンプルされます．
各文書に対して，上式を用いて各トピックの確率を計算することでトピックの確率分布（実際には正規化されていない）が得られます．しかし，この確率は正規化されていないので，正規化しなければいけません．
著者実装では，正規化されてないパラメータを用いたランダムサンプラー（？）的な何かを使ってサンプリングしていましたが，私は普通に多項分布を用いてサンプルしました．
多項分布を用いてサンプルする際は，一般に正規化された確率を引数に渡してあげなければならないのですが，上式から分かる通り，であるため，underflowしないようにlogsumexp1等を使わなければならないことに注意です．
logistic normalパラメータのサンプリング
次のような生成過程を考えてみます．
をガウス分布から生成
をロジスティック変換する: 
それぞれの文書に対して，トピックを生成: 
このとき，はロジスティック分布のCDFとも解釈することができます:
よって，トピックは下図のように多項分布からサンプルされることになります．
CDF上のの点を通るvertical lineを引く．
補助変数をそれぞれの文書に対し，一様分布からサンプルする: 
を上にプロットする．
もしがCDF曲線よりも下に位置するなら（よりも小さければ），z = kとする．上に位置するならz  kとする．
同様に，の初期値が決まっていれば，からを推定することもできます．k番目のトピック分布のパラメータを推定すること考えます．
まずは補助変数を次のように生成し，
CDF上，現在のの点を通るvertical lineを引く．
それぞれの文書に対して
z = kの場合，を次の一様分布から生成: 
z  kの場合，を次の一様分布から生成: 
全ての文書に対して補助変数を得たら，の推定範囲は次のようになります．
ただし，Cは定数で
となります．あとは，事前分布はガウス分布なので，この範囲で切断された，平均，分散の切断正規分布からサンプルすればよいです．
Tipsとして，n個の一様分布からサンプリングされた確率変数はベータ分布に従う性質を使うと，補助変数はn個全て生成する必要なく，計算量を削減できます．
単語分布についても，トピック分布と同様に補助変数法を用いてサンプルを行います．
トピック分布においては，文書の数だけ補助変数を生成しましたが，これを文書*各文書毎に現れる単語数分だけ生成し，単語分布を更新していきます．
結果
COHA (Corpus of Historical American English) を使って実験しました．1810-2009までの文書があり，冒頭で説明した通り，解析対象の単語の周辺単語を抜き取って文書を作成し，対象単語ごとにモデルを作成しました．
以下では”transport”を対象に学習を行なった結果を示します．
実際に各時点におけるトピック分布とトピック毎の確率の高い単語の可視化なんかも載せたいのですが，研究室にあるコーパスを使用しての実験となるため本サイトでの公開は控えさせてもらいます．ひとまずperplexityの推移のみ掲載します．
python等だと標準実装されているはずなので特に意識することなく使える気がしますが，僕はc++で実装したので次の資料を参考にしながら自前で実装しました: https://cl.naist.jp/?plugin=attach&refer=DMLA%2F2005%C7%AF%C5%D9&openfile=2005-06-07.pdf
[return]
