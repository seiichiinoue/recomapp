A Bayesian Model of Diachronic Meaning Changeの実装
今回実装したのは，通時的な意味変化を捉えるトピックモデルです．2016年のTACL論文になります．以下論文です．
https://www.aclweb.org/anthology/Q16-1003.pdf
実装後に発見したのですが，一応著者が公開している実装もあるらしいです（しかしGoで書かれていて，超絶読みづらいです）．
僕の実装は以下になります:
https://github.com/seiichiinoue/scan
Dynamic Bayesian Model of Sense Change (SCAN)
前置きとして，このモデルは単語の意味変化を捉えるためのモデルになっています．
データが少し特殊で，word-specific documentsを用いて学習します．意味変化を検出したいtarget wordの周辺単語を任意の文脈窓幅について
というような文書を仮定します．
この文書に対して，year label (正確な年は必要なく，どの文書集合がどの年代のものかがわかればよい) が付与されていて，その文書のyear labelを使って時期ごとにパラメータを設定し，それぞれの時期間に相関を持たせながら学習するようなモデルになっています．
本モデルでは，時点のtemporal meaning representationとして，K次元のトピック分布とV次元の単語分布を仮定します．また，時点間でのトピック分布の変化を制御するための精度パラメータであるを導入します．
上述の精度パラメータを使って，どのように時点間の相関をもたせるかですが，それは多項分布, の事前分布にlogistic normalを置くことで実現します．logistic normalに従う多項分布パラメータは，次元のランダムベクトルが次元の平均ベクトル，次元の分散共分散行列によるガウス分布から生成され:
それを次のようにロジスティック変換することにより単体上に射影する（0 ~ 1の確率に変換する）ことで生成されます．
このように事前分布にガウス分布を置くことで，分散を通してパラメータの変化の度合いをコントロールできます．
以下にSCANのグラフィカルモデルと生成モデルを示します．
まず，トピック精度パラメータを共役事前分布であるGamma分布から生成します．
次に，それぞれの時点において，logistic normal事前分布からトピック分布を生成し，それぞれのトピックについて，同様にlogistic normal事前分布から単語分布を生成します．
そして，各文書に対して，トピックを多項分布から生成し，文脈窓幅回文脈単語を多項分布から独立に生成する流れになります．
ここで，トピック分布 (論文中ではsense distributionと呼ばれている) と単語分布について，時点と時点のパラメータの平均を事前分布の平均としていますが，これは，intrinsic Gaussian Markov Random Field (iGMRF) であり，時期間のパラメータに相関を持たせ，変化を捉えることを可能としています．
推論
SCANの推定パラメータは，潜在変数である文書のトピック，トピック分布，単語分布，トピック分布のlogistic normal事前分布のパラメータです．
推定にはblocked Gibbs Samplerを用います．一般に，トピックモデルは多項分布-Dirichlet分布を用いて離散変数のモデル化を行うことが多いのですが，SCANは多項分布の事前分布に共役ではないガウス分布を仮定しているので，同様に推定することはできません．
そのため，Mimnoらから提案された補助変数を用いたlogistic normal priorに従うパラメータ推定法を用います．
大まかな流れとしては，文書のトピックを他のパラメータを固定した状態でサンプルし，次にトピックと単語の多項分布のパラメータを同様に他のパラメータを固定してサンプルし，最後に精度パラメータをサンプルする，という感じです．
トピックのサンプリング
文書のトピックは，他のパラメータを全て固定した上で以下の条件付き確率に従ってサンプルされます．
各文書に対して，上式を用いて各トピックの確率を計算することでトピックの確率分布（実際には正規化されていない）が得られます．
著者実装では，正規化されてないパラメータを用いたランダムサンプラー（？）的な何かを使ってサンプリングしていましたが，私は普通に多項分布を用いてサンプルしました．
多項分布を用いてサンプルする際は，一般に正規化された確率を引数に渡してあげなければならないのですが，上式から分かる通り，であるため，underflowしないようにlogsumexp1等を使わなければならないことに注意です．
logistic normalパラメータのサンプリング
上述の通り本モデルでは，多項分布の事前分布に共役でないlogistic normalを考えているので，LDAなどで用いられるサンプリング手法は用いることができません．
logistic normalパラメータを推定する方法として，Polya-Gamma分布を用いたサンプリング2がありますが，本実装では，補助変数を用いた推定方法を用いました．
次のような生成過程を考えてみます．
をガウス分布から生成
をロジスティック変換する: 
それぞれの文書に対して，トピックを生成: 
このとき，はロジスティック分布のCDFとも解釈することができます:
よって，トピックは下図のように多項分布からサンプルされることになります．
CDF上のの点を通るvertical lineを引く．
補助変数をそれぞれの文書に対し，一様分布からサンプルする: 
を上にプロットする．
もしがCDF曲線よりも下に位置するなら（よりも小さければ），z = kとする．上に位置するならz  kとする．
同様に，の初期値が決まっていれば，からを推定することもできます．k番目のトピック分布のパラメータを推定すること考えます．
まずは補助変数を次のように生成し，
CDF上，現在のの点を通るvertical lineを引く．
それぞれの文書に対して
z = kの場合，を次の一様分布から生成: 
z  kの場合，を次の一様分布から生成: 
全ての文書に対して補助変数を得たら，の推定範囲は次のようになります．
ただし，Cは定数で
となります．あとは，事前分布はガウス分布なので，この範囲で切断された，平均，分散の切断正規分布からサンプルすればよいです．
Tipsとして，n個の一様分布からサンプリングされた確率変数はベータ分布に従う性質を使うと，補助変数はn個全て生成する必要なく，計算量を削減できます．
単語分布についても，トピック分布と同様に補助変数法を用いてサンプルを行います．
トピック分布においては，文書の数だけ補助変数を生成しましたが，これを文書*各文書毎に現れる単語数分だけ生成し，単語分布を更新していきます．
結果
COHA (Corpus of Historical American English) を使って実験しました．1810-2009までの文書があり，冒頭で説明した通り，解析対象の単語の周辺単語を抜き取って文書を作成し，対象単語ごとにモデルを作成しました．
以下では”transport”を対象に学習を行なった結果を示します．
以下perplexiyの推移です．
トピック確率と単語分布を用いて，各時点における支配的なトピックと推移，また確率上位の単語を可視化しました．
凡例には1810年におけるトピック毎の確率上位単語を10個載せました．
茶色で示されるトピックは，joyやheartなどが確率上位となっており，昔はそういった単語と共起する確率が高かったことがわかります（自分は，単語の意味変化に詳しくないのですが，昔はa transports of joy的な使われ方をしていたみたいです3）．また，茶色で示されるトピックは昔は支配的であったのに対し，現在になるにつれて，支配率が低くなっていることもわかります．
現在は，青色で示されるトピック，つまり流通や移動手段に関する単語として使われることが多いこともわかりました．
まとめ
意味変化を捉える研究は大量にあって（自分は全て網羅できているわけでは到底ありません），研究室の先輩は単語分散表現を用いて意味変化の検出を行うといったことをしてたりするんですが，トピックモデルを使うと解釈がしやすく，分析をする際は有用だなと思いました．
今回実装したモデルはword-specific documentsを使った意味変化のトピックモデルで，target wordをあらかじめ決めることでその周辺単語集合をモデル化する手法でした．実際の用途としては「統計的に意味変化があった単語を発見したい」ということが多いので，target wordをあらかじめ決めることなく同様のモデリングができたら面白そうだな，と思ってます．
python等だとライブラリがうまくやってくれるはずなので特に意識しなくていいです．
[return]
LindermanらのDependent Multinomial Models Made Easy: Stick Breaking with the Polya-Gamma Augmentationが詳しいです．
[return]
「喜びに我を忘れて」という意味らしい
[return]
