トピック モデル を 用い た 類似 記事 の レコメンド 機能 の 実装 
久々 の 更新 と なり ます ． トピック モデル による 文書 分類 を 用い て この ブログ の レコメンド 機能 を 実装 し た ので ， まとめ て いき たい と 思い ます ． 
大まか な 流れ として は ， ブログ の 全 文書 を 用い た モデリング ， モデル の API 化 ， API の デプロイ ， DOM を いじっ て 結果 を 表示 ， という 感じ に なっ て い ます ． かなり 単純 な の です が ， 自分 にとって は 初めて の こと が 多かっ た ので （ 特に web に関する こと で ） 備忘録 的 な 形 で も 残せ たら な と 思っ て 書い て いき ます ． 
まず ， トピック モデル は ， 様々 な 離散 データ に 隠れ た 潜在 的 な トピック を 推定 する モデル です ． ここ で いう トピック と は ， 自然 言語 処理 の 文脈 で は ， 話題 や 分野 に 対応 する と 考え られ ， 購買 データ など で は ， 消費 者 の 嗜好 など に 対応 する と 考える こと が でき ます ． 
また ， ナイーブベイズ 分類 器 など と は 異なり ， 完全 に 教師 なし （ 人手 を 介さ ない ） で データ から 自動的 に 学習 する モデル と なっ て い ます ． 
今回 は ， その トピック モデル の ひとつ で ある LDA ; Latent Dirichlet Allocation を 用い て この ブログ の モデリング を 行い まし た ． 
LDA ; Latent Dirichlet Allocation 
LDA は ざっくり と 以下 の よう な モデル に なり ます ． 
文書 の 背景 に は 「 トピック の 適合 率 」 が 存在 し て いる 
文書 中 の 各 単語 の 背景 に は ， 一つ の トピック が 存在 し て いる 
各 単語 の 背景 に ある トピック は ， その 単語 が 属し て いる 文書 の 「 トピック の 混合 率 」 から 生成 さ れる 
つまり ， LDA による 文書 群 の モデル 化 が できれ ば ， 任意 の 単語 に対して ， 単語 の 背景 に ある トピック が 推定 可能 な ので ， 同じ トピック に 属する 単語 を 探す こと で その 単語 と 同じ よう な 意味 を もつ 単語 で クラスタリング する こと が でき ます ． また ， 文書 について も 同様 に ， 各 文書 の 背景 トピック を 見れ ば ， 文書 の クラスタリング も 可能 に なり ます ． 
LDA の 生成 モデル 
LDA で は ， まず ， 文書 を トピック の 混合 比 (= 潜在 トピック 分布 ) で 表現 し ます ． 各 文書 の トピック は 多項 分布 に 従う ので ， その トピック の 混合 比 は ， 多項 分布 の 共役 事前 分布 の ディリクレ 分布 から 生成 さ れる と 考え ます ． 
次に ， 文書 において トピック が 生成 さ れ たら ， その トピック における 単語 の 生起 確率 分布 を 考え ます ． こちら も 多項 分布 に 従う ので ， 同様 に ディリクレ 分布 から 生成 さ れる と 考え ます ． 
そして ， 各 単語 は ， 単語 が 属する 文書 が もつ トピック における 単語 の 生起 確率 分布 に従って 生成 さ れ ます ． 
以上 の LDA における 単語 の 生成 モデル の 流れ を まとめる と ， 以下 の よう に なり ます ． 
トピック の 混合 比 を 生成 
For n = 1 … N , 
トピック を 選択 
単語 を 生成 
これ が 生成 モデル です が ， もちろん 現実 に は 文書 ， つまり 単語 の カウント 数 という データ が ある だけ で ， この 生成 過程 は わかっ て い ませ ん ． それ を データ から 求め ます ． 
LDA の 解法 
単語 生起 確率 が で ， 各 単語 の 背景 トピック が で ある よう な 文章 群 が 得 られる 確率 は 以下 の よう な 図 ( グラフィカルモデル ) によって 表現 さ れ ， 
その 実態 で ある ， 観測 単語 と トピック ， トピック 分布 の 同時 確率 関数 は 以下 の よう に なり ます ． 
よって ， 文書 について 
と なり ， これ が 尤 度 関数 と なり ます ． この 尤 度 を 最大 に する とき の パラメータ を 推定 し たい です ． 
推定 方法 は いくつ か あり ます が ， 今回 は Gibbs サンプラー を 用い て 1 推定 し まし た ． 
LDA の Gibbs Sampler 
Gibbs サンプラー と は ， マルコフ 連鎖 モンテカルロ 法 ( MCMC ) の 最も 簡単 な 場合 で ， 潜在 変数 を 分布 で は なく ， 条件 付き 分布 から 実際 に サンプリング し て いく こと で パラメータ の 推定 を 行う 手法 です ． 
潜在 変数 を 持つ 確率 モデル 
$ 
が ある 時 ， 各 を 考え直す ， つまり 条件 付き 分布 
から ランダム に サンプリング する こと を 繰り返し ます ． 
また ， EM アルゴリズム と は 違い ， 原理 的 に 無限 回 繰り返せ ば 真 の 分布 から の サンプル に なり ます ． つまり ， 局所 最適 に 陥ら ず 大域 的 最適 解 を 得 やすい という こと に なり ます ． 
LDA の 潜在 変数 は ， 文書 の トピック 分布 と 各 単語 の トピック ， トピック 毎 の 単語 の 生起 確率 分布 です が ， ここ で はと を 積分 消去 し て ， 尤も らしい 得る こと を 考え ます ． つまり 
から を サンプリング し て 更新 し て いく こと で ， 尤も らしい を 得 ます ． 
ここ で ， は ， 
で ， は ， データ 全体 で 単語 が トピック に 割り当て られ た 回数 ( を 除く ) で あり ， は ， 文書 中 で トピック に 割り当て られ た 単語 数 ( を 除く ) です ． 
LDA の 幾何 学 的 解釈 
LDA は ， 名前 の 通り ， 潜在 ディリクレ 分布 に allocate する という もの です が ， 何 を 何 に allocate し て いる の でしょ う か ． ここ で ， 3 - 1 = 2 次元 の 単体 上 で の 生成 の 流れ を み ながら ， LDA を 再 解釈 し て み ます ． 
LDA で は ， 文書 毎 に トピック 単体 上 の ディリクレ 分布 から トピック 分布 を 選択 し ます ． ここ で ， 単体 の 角 が 各 トピック に 対応 し て い ます ． そして ， から 確率 的 に 頂点 を 選び ， から 確率 的 に を 選び ます ． 
これ は ， から 直接 を 選ん で いる こと と 等価 です ． つまり ， トピック 単体 は 単語 単体 上 に 埋め込ま れ て いる という こと が わかり ます ． 
よって ， 文書 を 比較的 大きい と 考え られる 単語 次元 より も 低 次 の 単体 に ” allocate ” する という の が LDA の 名前 の 所以 に なっ て いる よう です ． 
LDA による 文書 分類 
さて ， LDA の こと が なんとなく わかっ た ので ， LDA を 用い て 文書 分類 を 行っ て いき ます ． LDA で 文書 分類 を 行う 方法 は ， いくつ か 考え られ ます が ， ここ で は 文書 が 持つ トピック 分布 を 用い て 分類 を 行い ます ． 
は トピック 分布 で あり ， 上述 の 通り ディリクレ 分布 に 従う ので ， の 期待 値 を 以下 の よう に 求め て あげれ ば よい です ． ただし ， は Newton - Raphson 法 など で 最 尤 推定 し ます ． 
ここ で ， 類似 する 記事 := 同じ トピック を 持つ 記事 と 定義 し て あげ て ， 同じ トピック を 持つ 記事 で クラスタリング し て あげれ ば 分類 が でき ます ． レコメンド も ， 同じ クラスタ に 属する 文書 を 用いる こと で 実現 でき そう です ． 
つまり ， 記事 と 類似 する 記事 の 集合 を と する と ， 
が 類似 する 記事 の 集合 と なり ， これ を レコメンド すれ ば 良い です ． ここ で は 文書 における 各 トピック の 期待 値 です ． 
システム の 概要 
レコメンデーション の アルゴリズム まで 考える こと が でき た ので ， 次 は 構築 し た モデル を webAPI に し て ， web 上 で 動く よう に し ます ． 
API の 作成 に は python の Flask 2 を 用い まし た ． 実装 は seiichiinoue / recomapp に あり ます ． 
API で は ， レコメンド を 取得 し たい 対象 の 記事 の pathname を 投げ た 時 に ， レコメンド 結果 を json で 返す という よう な 単純 な こと を し て い ます ． 以下 の よう に 取得 できる よう に し て い ます ． 
それから ， heroku で API を デプロイ し たら web 上 で 動く 推論 モデル の 完成 です （ すげ ー ！ ） 
無事 API を デプロイ でき た ので ， あと は フロント 側 から javascript で DOM を いじっ て あげ て ， 各 記事 に 適切 な レコメンデーション 記事 の リスト を 表示 すれ ば 完成 です ． 
javascript に は ， DOM ; Document Object Model という HTML に javascript から アクセス できる よう に し た オブジェクト 構造 が あり ます ． 今回 は ， 静的 ジェネレータ を 用い た ブログ 内 で webAPI を通して 取得 し た データ を もと に 動的 に ページ を 生成 し たかっ た ので ， 簡単 な javascript を 用い まし た ． 
例えば ， この ページ の この 箇所 は 
この よう に アクセス する こと が でき ， この オブジェクト に は メソッド が 用意 さ れ て いる ので ， 予め ” See Also ” の フィールド を 作っ て おい て あげ て ， DOM 側 から その Element に リスト を 追加 すれ ば 簡単 に レコメンド を 表示 でき ます ． 
まとめ と 展望 
とりあえず ， 以上 の よう に 統計 モデル を 使っ て （ 記事 へ の タグ 付け など 人手 を 介さ ず ） レコメンデーション を 自動 化 する こと が でき まし た ． 
しかし ， 結果 は 各 記事 ( に あり ます ) を み て いただき たい の です が ， 現時点 で は ブログ で の 記事 数 が 少なく ， 文書 数 / 語彙 数 と共に 本来 の 分布 を 正確 に 推定 できる に は 事足り ず ， 推論 結果 が 納得 の いく もの に は なり ませ ん でし た ． 文書 数 を 増やす こと は もちろん です が （ 頑張り ます ！ ） ， 前 処理 の 時点 で 数式 や コード ブロック を バッサリ と 捨て て しまっ て い たり と 無駄 に なっ て いる 記号 の 情報 が 多い ので ， そこら へん の 情報 を 使用 し たら 現状 下 で も もう少し 精度 が 上がる の で は ない か と 思い まし た ． 
また ， API に関して です が ， 現時点 で は 記事 が 追加 さ れる 度 に 自分 で モデル を 再 学習 さ せ て ， デプロイ し なおし て おり ， 効率 的 と は 言え ませ ん ． ci など を 用い て 記事 が 追加 ( ブログレポジトリ の master ブランチ に ファイル が push ) さ れ た 時 に ， 自動 で モデル を 再 学習 / ビルド / デプロイ を できる よう に でき たら より 嬉しい か な と 思い まし た ． 
参照 
統計数理研究所 離散 データ の 確率 的 トピック モデル , 持 橋 大地 , 生物 に 見 られる 時 空間 パターン と 統計 数理 : 同調 ・ 認知 ・ 行動 にて ( 2015 ) 
Latent Dirichlet Allocation , Blei , Ng , Jordan , Journal of Machine Learning Research 3 ( 2003 ) 
Probabilistic Topic Models , Blei , Communications of ACM ( 2012 ) 
Gibbs サンプラー は 変 分 ベイズ と 比べ て 計算 量 が 多い らしい です が ， 今回 用い た データ は 自分 の ブログ の 文書 のみ で あり ， リソース に は 余裕 が あっ た ため ， 局所 解 に 陥り にくい Gibbs サンプラー を 採用 し まし た ． 
[ return ] 
Python 用 の 軽量 な ウェブアプリケーションフレームワーク です 
[ return ] 
See Also 
