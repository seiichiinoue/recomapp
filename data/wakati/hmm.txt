Hidden Markov Model の 実装 
隠れ マルコフ モデル による 教師 なし 品詞 推定 の 実装 を 行い まし た ． 実装 は seiichiinoue / hmm に 公開 し て い ます ． 
品詞 推定 
品詞 の 推定 と は 文 が 与え られ た 時 の 品詞 列 を 予測 する もの です ． 
実際 に は ， 解決 策 は 多く あり ， 各 単語 を 個別 に 予測 する 点 予測 で は ， パーセプトロン を 用い た KyTea など が あり ます ． また ， 系列 に対する 生成 モデル に は ， 隠れ マルコフ モデル を 用い た ， ChaSen など が あり ます ． 今回 は 後者 の 隠れ マルコフ モデル を 用い た 品詞 推定 の 実装 を 行い まし た ． 
モデル で は ， 文 が 与え られ た 場合 の 最も 確率 の 高い タグ 列 を 計算 し ます ． 
これ を ベイズ 則 で 分解 し ます ． 
すると ， 第 2 式 の は ， 単語 と 品詞 の 関係 を 考慮 し て おり ， は 前 の 品詞 と 次 の 品詞 の 関係 を 考慮 し て いる もの と 解釈 する こと が でき ます ． 
これ が 系列 に対する 生成 モデル に なり ます ． 
隠れ マルコフ モデル ( HMM ) 
マルコフ モデル は 複数 の 状態 を 持ち ， ある 状態 から 別 の 状態 へ 一定 の 確率 で 遷移 し ます ( 天気 の 例 とか で み た こと が ある と 思い ます )． この 確率 を 遷移 確率 と 呼び ， 状態 の 遷移 後 ， その 状態 に 依存 し た 一定 の 確率 で 出力 記号 を 出力 し ます ． この 確率 を 出力 確率 と 呼び ます ． 
図 で 表す と 以下 の よう な 動作 に なり ます ． 
まず ， 初期 状態 を 表す 特殊 な 状態 から に 遷移 し ます ． 遷移 し たら から 出力 記号 を 生成 し ， 出力 し ます ． 
次に ， に従って 遷移 先 を 決定 し ます ． 遷移 し たら から 出力 記号 を 生成 し ， 出力 し ます ． 
今回 は 品詞 推定 を 扱う ので ， 状態 が 品詞 に 対応 し ， 出力 記号 が 単語 に 対応 し ます ． 
品詞 から 品詞 へ の 遷移 確率 は ， 
と なり ， 品詞 から 単語 の 出力 確率 は ， 
と なり ます ． 
また HMM で は ， 遷移 確率 と 出力 確率 を 次 の よう に 表し ます ． 
ここ で は 状態 数 を 3 ， 出力 記号 数 を 2 と し て い ます ． 実際 に は 上述 の 通り ， 状態 数 は 品詞 の 数 に なり ， 出力 記号 数 は ， 単語 数 に なり ます ． 
（ 遷移 確率 が あらかじめ 与え られ て いる の は HMM モデル で は なく ， ただ の マルコフ モデル な ので ， ここ で は ， 上 の 行列 は 推定 し た 遷移 確率 行列 と 考え て ください ． ） 
この 行列 は 行 が 品詞 を 表し て おり ， 列 が 遷移 先 の 品詞 と 出力 記号 に 対応 し て い ます ． 
簡単 の ため ， 図 中 で は 時刻 を 表す 添字 を つけ て あり ます が ， 実際 は 時刻 に 関係 なく 同じ 行列 を 使用 し ます ． 
HMM の 学習 
以下 ， HMM の パラメータ を 推定 する にあたって ， モデル を 表現 する ため の 記号 を 整理 し て おき ます ． 
: 観測 回数 
: 状態 数 
: 出力 記号 の 数 
: 番目 の 状態 
: 番目 の 出力 記号 
: 時点 で の 状態 
: 時点 で の 観測 結果 
: 状態 系列 
: 出力 記号 系列 
: 状態 から 状態 へ の 遷移 確率 
: 状態 で を 出力 する 確率 
: 初期 状態 が で ある 確率 
: を () 成分 として もつ の 行列 
: を () 成分 として もつ の 行列 
: を 成分 として もつ 行列 
HMM の 学習 は ， 大きく 分け て 3 つ の 問題 を 解く こと によって 実現 し ます ． 
一つ 目 は ， パラメータ を 既知 と し た とき ， 出力 記号 列 として の 観測 結果 が 得 られる 確率 を 求める 評価 の 問題 です ． 二つ 目 は ， パラメータ を 既知 と し た とき ， 観測 結果 を 導く 可能 性 の 最も 高い 状態 系列 を 求める 復号 の 問題 です ． そして 三つ 目 が ， パラメータ を 未知 と し た とき ， 観測 結果 から 未知 パラメータ を 求める 推定 の 問題 です ． 
これら を 順番 に 説明 し て いき ます ． 
出力 確率 の 計算 
は 出力 記号 列 で あり ， ( は 事前 分布 ) を 与え られ た モデル と する と ， 出力 確率 が 知り たい ので ， 求め たい 値 は に なり ます ． 
を 状態 列 と する と ． 出力 確率 の 定義 より ， 
と なり ます ． また ， と の 定義 により ， 
で ある ので ， 
と なり ， 
を 得 ます ． そして ， これ を について 周辺 化 する こと で ， 以下 の よう に を 得る こと が でき ます ． 
しかし ， これ を 計算 する に は ， 膨大 な 時間 が かかる ため ()， HMM で は ， forward アルゴリズム を 使用 し て 計算 し ます ． 
forward アルゴリズム で は ， と ， に対して ， 
を 用い ます ． は マルコフ 状態 が で ある 時点 まで の 観測 結果 の 同時 確率 です ． 
は 以下 の よう に 計算 さ れ ます ． 
に対して ， と する ． 
と に対して ， 以下 を 計算 する ． 
まで この 作業 を 行う と ， 以下 の よう に ， 出力 確率 が 算出 さ れ ます ． 
以上 の forward アルゴリズム を 使用 する こと で ， だっ た 計算 量 が ， に なり ます ． 
隠れ 状態 の 推定 
モデル と 文字 列 が 与え られ た 時 ， 最も 尤も らしい 隠れ 状態 の 列 を 求める ため に ， HMM で は backward アルゴリズム を 使用 し て 計算 し ます ． 
backward アルゴリズム で は ， 出力 確率 の 計算 の 時 と 同様 に と ， に対して ， 
を 定義 し ます ． は 以下 の よう に 計算 さ れ ます ． 
に対して ， と する ． 
と に対して ， 以下 を 計算 する ． 
ここ で ， と に対して ， 
を 定義 し ます ． また ， は 時点 まで の 確率 ， は 時点 以降 の 確率 に なっ て いる こと から ， 
で あり （ 分母 の は を で 周辺 化 すれ ば 得 られ ます ） ， この を 最大 化 する よう に 隠れ 状態 を 決定 すれ ば 良い こと に なり ます ． 
モデル の 推定 
出力 確率 と 隠れ 状態 を 算出 でき た ので ， それら を 用い て ， 観測 データ に 最も フィット する モデル の パラメータ の 調整 を 行い ます ． 
まず ， と ， に対して ， 以下 を 定義 し ます ． 
よって は ， 時刻 に と なり ， 時刻 に に 遷移 する 確率 です ． そして 上 式 は を 用い て ， 以下 の よう に 表す こと が でき ます ． 
また ， において と の 間 に は 以下 の 関係 が あり ます ． 
と di - gamma が 与え られ た ので ， は 以下 の よう に 推定 する こと が でき ます ． 
に対して ， 
と ， に対して 以下 の よう に を 計算 する 
と に対して 以下 の よう に を 計算 する 
の 推定 式 の 分子 は ， 状態 から へ の 遷移 の 期待 値 を 表し て おり ， 分母 は ， 状態 から あらゆる 状態 へ の 遷移 の 期待 値 を 表し て い ます ． 
また ， の 推定 式 の 分子 は ， の 時 に モデル が 隠れ 状態 だっ た 回数 の 期待 値 ， 分母 は ， モデル が 隠れ 状態 だっ た 回数 の 期待 値 を 表し て い ます ． 
これ まで の 過程 を まとめる と ， モデル の 推定 は 以下 の よう に 行う こと が でき ます ． 
を 初期 化 
を 計算 する 
を 再 推定 する 
が 上昇 すれ ば ， 2 に 戻る ． 
Viterbi アルゴリズム 
viterbi アルゴリズム は ， モデル において 最適 な 状態 系列 （ 最適 経路 ） と ， その 経路 上 で の 確率 を 求める 動的 計画 法 を 用い た アルゴリズム です ． 
まず モデル において ， 連続 し た 観測 系列 に対する 最適 な 系列 を 求める ため に ， 時刻 で 状態 に 至る まで の 最適 状態 確率 を 定義 し ます ． 
また ， 時点 における 最適 状態 確率 は ， 次 の よう に 導出 でき ます ． 
ちなみに ， これ は forward アルゴリズム で 導出 し た 式 と ほとんど 一緒 で ， 異なる の は ， forward アルゴリズム で は ， 合計 を とっ て い た ところ を ， viterbi アルゴリズム で は ， 最大 値 を とっ て いる ところ です ． 
時点 ， 状態 において ， 出力 確率 を 最大 に する 経路 （ 状態 遷移 ） を ， 最適 経路 の 出力 確率 を ， 最適 経路 上 の 最終 状態 を と する と ， 最適 経路 および 出力 確率 は 以下 の よう に し て 求める こと が でき ます ． 
と を 初期 化 する 
それぞれ を 計算 する 
結果 を 格納 する 
状態 系列 を 復元 する 
実験 
隠れ 状態 = 30 ， イテレーション = 200 で 学習 を 行い まし た ． 
以下 は wikipedia 日本語 コーパス を 使用 し て ， 実際 に 学習 さ せ た 結果 です ． 正解 率 は 67 . 1 % でし た ． 
以下 は 我輩 は 猫 で ある の 全文 の 学習 結果 です ． 正解 率 は 78 . 8 % でし た ． 
以下 は こころ の 全文 の 学習 結果 です ． 正解 率 は 83 . 5 % でし た ． 
初めて の 実装 に し て は ， うまく いっ て 満足 でし た ． 収束 速度 が 遅かっ たり ， 未知 語 へ の 対応 として の スムージング など を 行なっ て い なかっ たり と まだまだ 改善 点 が あり そう な ので ， 少し ずつ やっ て いき たい と 思い ます ． 
See Also 
